\documentclass[a4paper,10pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage{fullpage}
\usepackage[parfill]{parskip}
\usepackage{multicol}
\usepackage{url}
\usepackage[hmargin=.5in,vmargin=.5in]{geometry}


%opening

\begin{document}
\begin{center}

\textbf{SUNY Albany}

\textbf{MAT810 Spring 2022}

\textbf{Advanced Topics in Machine Learning}


\end{center}

\textbf{Instructor:} Felix Ye 

\textbf{Lectures:} MW 11:40am - 1pm  in Massry Ctr for Business 356.

\textbf{Instructor Office Hours:} Mo 1:30PM-2:30PM, We 10:30AM-11:30AM


\textbf{E-Mail Address:} xye2@albany.edu\\
Email will be a major line of communication between the student and the instructor. I will send urgent announcements and important information via email. Please check your university email regularly.

\textbf{Web Page:}
Check the course page in blackboard regularly. Homework assignments, course announcements, and grades will be posted there.


\textbf{Course Description:}   Machine Learning algorithms are on the rise. Each year new techniques are presented that outdate the current leading algorithms. Some of them are only little advances or combinations of existing algorithms and others are newly created and lead to astonishing progress. This course gives an overview of recent state of the art algorithms (although most of them are outdated already). The main theme of this course is to implement these algorithms from scratch. It is the key to understand how these ``wheel" works. 

This course is the second part of a two-semester sequence that focuses on theoretical and practical aspects of machine learning. The course will mainly focus on more algorithms for unsupervised data analysis, including manifold learning, spectral clustering, autoencoders, GAN.  The programming language in this course will be Jupyter notebook. 

All latest jupyter notebook can be downloaded in https://github.com/yexf308/AdvancedMachineLearning.git. I will keep updating this git repository as class progresses, so please fetch the update regularly. I will also leave a copy (not most updated) version in blackboard. 

 Prerequisite: AMAT592 or I CSI 436 or any other machine learning courses. 
 

\textbf{Textbook:} 

Probabilistic Machine Learning: An Introduction \\
Nonlinear Dimensionality Reduction \\




\textbf{Grading Policy:}

\begin{tabular}{lr}
Homework & 70\%\\ 
Final project & 30\% \\
\end{tabular}

Incomplete grade: This class will not give any
incomplete grade. If the work cannot complete in the
current semester, the student can choose to retake this
class in the following year.




\textbf{Exams:} There will be one final project. The detail will be given at the end of the semester. 


\textbf{Homework:} Homework assignments will be assigned each month. There are 4 sets of homework in total. 

Students may work in groups although solutions and code must be prepared individually.

Late assignment turn-in is not permitted. Any assignment turned in after the deadline will NOT be graded.




\textbf{Attendance:} Although attendance will not be taken, I strongly encourage you attend and participate in every lecture. This is one of the best ways to ensure success in the course.






\textbf{Academic Misconduct:} The strength of the university depends on academic and personal integrity. In this course, you must be honest 
and truthful. Ethical violations include cheating on exams, plagiarism, reuse of assignments, improper use 
of the Internet and electronic devices, unauthorized collaboration, alteration of graded assignments, forgery 
and falsification, lying, facilitating academic dishonesty, and unfair competition.

In addition, specific ethics guidelines for this course are as follows: Students may discuss homework. However, 
all solutions MUST be written up and submitted individually. The same rules apply to computer programs. 
Basic ideas may be discussed but detailed codes should not be copied or shared. Finally, exams must 
represent the result of individual effort and communication is permitted only with the instructor.

Report any violations you witness to the instructor. You may consult the associate dean of student affairs 
and/or the chairman of the Ethics Board beforehand. 

\textbf{Tentative Course Outline and Schedule:}


\begin{itemize}

\item Week 1 (Jan 24 \& Jan 26): Intro to Manifold Learning. MDS. HW 1 assigned. 

\item Week 2 (Jan 31 \& Feb 2): Isomap and  Randomized SVD


\item Week 3 (Feb 7 \& Feb 9):  Random projection and Laplacian Eigenmaps 

\item Week 4 (Feb 14 \& Feb 16): Laplacian Eigenmaps and Spectral clustering.  HW1 due. HW2 assigned.

\item Week 5 (Feb 21 \& Feb 23):  Diffusion map

\item Week 6 (Feb 28 \& Mar 2): PageRank and Locally linearly embedding

\item Week 7 (Mar 7 \& Mar 9): t-SNE. HW2 due. HW3 assigned. 

\item Spring Breaks.

\item Week 8 (Mar 21 \& Mar 23): Project Guide. UMAP

\item Week 9 (Mar 28 \& Mar 30): DBSCAN clustering.

\item Week 10 (Apr 4 \& Apr 6):  Recommendation systems. HW3 due and HW4 assigned.  

\item Week 11 (Apr 11 \& Apr 13):  Hidden Markov model.

\item Week 12 (Apr 18 \& Apr 20):  Auto-encoder.  HW4 due. 

\item Week 13 (Apr 25 \& Apr 27):  Generative adversarial networks(GAN).

\item Week 14 (May 2 \& May 4): Summary and Q\&A. 
 
\end{itemize}






\end{document}
