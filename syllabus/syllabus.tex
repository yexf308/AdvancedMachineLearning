\documentclass[a4paper,10pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage{fullpage}
\usepackage[parfill]{parskip}
\usepackage{multicol}
\usepackage{url}
\usepackage[hmargin=.5in,vmargin=.5in]{geometry}


%opening

\begin{document}
\begin{center}

\textbf{SUNY Albany}

\textbf{MAT810 Spring 2022}

\textbf{Advanced Topics in Machine Learning}


\end{center}

\textbf{Instructor:} Felix Ye 

\textbf{Lectures:} MW 11:40am - 1pm  in Massry Ctr for Business 356.

\textbf{Instructor Office Hours:} TBA


\textbf{E-Mail Address:} xye2@albany.edu\\
Email will be a major line of communication between the student and the instructor. I will send urgent announcements and important information via email. Please check your university email regularly.

\textbf{Web Page:}
Check the course page in blackboard regularly. Homework assignments, course announcements, and grades will be posted there.


\textbf{Course Description:}   Machine Learning algorithms are on the rise. Each year new techniques are presented that outdate the current leading algorithms. Some of them are only little advances or combinations of existing algorithms and others are newly created and lead to astonishing progress. This course gives an overview of recent state of the art algorithms (although most of them are outdated already). The main theme of this course is to implement these algorithms from scratch. It is the key to understand how these ``wheel" works. 

This course is the second part of a two-semester sequence that focuses on theoretical and practical aspects of machine learning. The course will have two parts. The first part will introduce more algorithms for unsupervised data analysis, including manifold learning, spectral clustering, autoencoders. The second part will focus on other state of the art machine learning algorithms on science and engineering, including CNN, RNN, Reservoir Computing and etc. The programming language in this course will be Jupyter notebook. 

All latest jupyter notebook can be downloaded in https://github.com/yexf308/AdvancedMachineLearning.git. I will keep updating this git repository as class progresses, so please fetch the update regularly. I will also leave a copy (not most updated) version in blackboard. 

 Prerequisite: AMAT592 or I CSI 436 or any other machine learning courses. 
 

\textbf{Textbook:} 

Probabilistic Machine Learning: An Introduction \\
Nonlinear Dimensionality Reduction \\




\textbf{Grading Policy:}

\begin{tabular}{lr}
Homework & 70\%\\ 
Final project & 30\% \\
\end{tabular}

Incomplete grade: This class will not give any
incomplete grade. If the work cannot complete in the
current semester, the student can choose to retake this
class in the following year.




\textbf{Exams:} There will be one final project. The detail will be given at the end of the semester. 


\textbf{Homework:} Homework assignments will be assigned each month. There are 3 sets of homework in total. 

Late assignment turn-in is not permitted. Any assignment turned in after the deadline will NOT be graded.




\textbf{Attendance:} Although attendance will not be taken, I strongly encourage you attend and participate in every lecture. This is one of the best ways to ensure success in the course.






\textbf{Academic Misconduct:} The strength of the university depends on academic and personal integrity. In this course, you must be honest 
and truthful. Ethical violations include cheating on exams, plagiarism, reuse of assignments, improper use 
of the Internet and electronic devices, unauthorized collaboration, alteration of graded assignments, forgery 
and falsification, lying, facilitating academic dishonesty, and unfair competition.

In addition, specific ethics guidelines for this course are as follows: Students may discuss homework. However, 
all solutions MUST be written up and submitted individually. The same rules apply to computer programs. 
Basic ideas may be discussed but detailed codes should not be copied or shared. Finally, exams must 
represent the result of individual effort and communication is permitted only with the instructor.

Report any violations you witness to the instructor. You may consult the associate dean of student affairs 
and/or the chairman of the Ethics Board beforehand. 

\textbf{Tentative Course Outline and Schedule:}


\begin{itemize}
\item Module 1: Unsupervised Learning
\item Week 1 (Jan 19): Review of stochastic process.  

\item Week 2 (Jan 24 \& Jan 26): Spectral clustering. HW 1 assigned. 

\item Week 3 (Jan 31 \& Feb 2): Manifold Learning: MDS and Kernel PCA

\item Week 4 (Feb 7 \& Feb 9): Manifold Learning:  Laplacian Eigenmaps and Isomap. 

\item Week 5 (Feb 14 \& Feb 16): Manifold Learning: diffusion map. HW1 due. 

\item Week 6 (Feb 21 \& Feb 23): Manifold Learning: Autoencoder. HW2 assigned.

\item Module 2: The state of the art in Machine Learning 
\item Week 7 (Feb 28 \& Mar 2): Compressed Sensing.

\item Week 8 (Mar 7 \& Mar 9): Hidden Markov Models. HW2 due. 

\item Spring Breaks.

\item Week 9 (Mar 21 \& Mar 23): State of the art Optimization Methods in Neural Networks.
 HW3 assigned.

\item Week 10 (Mar 28 \& Mar 30):Convolutional Neural Networks. 

\item Week 11 (Apr 4 \& Apr 6):  Recursive Neural Networks and Long Short Term Memories. 

\item Week 12 (Apr 11 \& Apr 13): Reservoir Computing. HW3 due. 

\item Week 13 (Apr 18 \& Apr 20): Ensemble Learning. 

\item Week 14 (Apr 25 \& Apr 27):  Boosting methods. 

\item Week 15 (May 2): Summary 
 
\end{itemize}






\end{document}
