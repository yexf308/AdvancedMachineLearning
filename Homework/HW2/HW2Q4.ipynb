{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2Q4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPgmg8fmf3lK9Tozo6qnAvy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yexf308/AdvancedMachineLearning/blob/main/Homework/HW2/HW2Q4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj3lZdL9L0WU",
        "outputId": "7d086a7e-70f5-4ff5-b833-60aa807a4390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "%pylab inline \n",
        "import numpy.linalg as LA\n",
        "from time import time\n",
        "from scipy.io import mmread\n",
        "from scipy.spatial import KDTree\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os \n",
        "os.chdir(\"/content/drive/My Drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7Cn0lwEXHWW",
        "outputId": "609d91c5-c440-4c4c-e60a-1a376196c018"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4: KD-Trees and LSH for Approximate Neighbor Finding (50pt)\n",
        "## Your group member: \n",
        "\n",
        "**Data access:** the data is stored in https://drive.google.com/file/d/1BZg1e5et1FGKXkq6szoUprvHQtsHvAx2/view?usp=sharing. Once you open the link in the brower, make sure you click the \"Add shortcut to Drive\" and now your google drive should show up the zip file. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In this problem, you will use KD-trees and Locality Sensitive Hashing (LSH) to find exact and approximate nearest neighbors. For datasets with high dimensionality $d$, KD-trees will not scale well and other methods must be used. LSH offers a method for reducing the dimensionality of the data while still enabling approximate neighbor finding.  For this portion of the problem, you will be using an artificially generated dataset consisting of term-document frequency for a vocabulary of size $d=1000$ and $N=100000$.\n",
        "\n",
        "The zip file consists of two files, `sim_docdata.mtx` and `test_docdata.mtx`,\n",
        "which contain the term frequencies in a sparse matrix in Matrix Market format: each row\n",
        "is in the form “termid docid frequency”. test docdata.mtx contains a set of documents\n",
        "to use for querying nearest neighbors. The size of the test set is 500 documents. "
      ],
      "metadata": {
        "id": "H2CRoGwvL7he"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip sim_docdata.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1ddOHyQXYx0",
        "outputId": "06c86786-da18-4f05-a361-2feff2b53dd0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  sim_docdata.zip\n",
            "  inflating: sim_docdata.mtx         \n",
            "  inflating: test_docdata.mtx        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = mmread('sim_docdata.mtx')\n",
        "X = X.T;\n",
        "test = mmread('test_docdata.mtx')\n",
        "test = test.T"
      ],
      "metadata": {
        "id": "9pkPQ9s0XdAz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay9qpDp8Xm9g",
        "outputId": "f47b3644-ae5f-4c3c-bda0-c6d9eec56a03"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 1000)\n",
            "(500, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q4.1 LSH\n",
        "Implement a nearest neighbor search using LSH and $d$ the number of\n",
        "projections, in $\\{5, 10, 20\\}$. Although normally we would search ’until time runs out’, for this problem, just search all bins that have a Hamming distance from the bin of the query data point $<=3$. Record the average query time and the average distance\n",
        "to the nearest neighbor for the test set."
      ],
      "metadata": {
        "id": "U8rWBK4iZ1Cq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code starts here"
      ],
      "metadata": {
        "id": "qXXcC3siaOcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q4.2 Kd-tree\n",
        "Direct implement Kd-tree is nearly impossible here since the dimension is too high. Implement a Gaussian random projection on the document data for $d$ in\n",
        "$\\{5, 10, 20\\}$. Use these projections as the entries for a KD-tree. This results in an\n",
        "alternative approximate nearest neighbor search.  Again,\n",
        "record the average query time and average distance over the test set. \n",
        "You can use `scipy` package KD-tree. Here is the [link](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.KDTree.query.html). "
      ],
      "metadata": {
        "id": "YOeEWQnObAHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code starts here"
      ],
      "metadata": {
        "id": "9XkGRB8ifhEf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}