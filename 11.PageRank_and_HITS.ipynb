{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PageRank and HITS.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP2ucSBT7fIGmXY4fdxWDv+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yexf308/AdvancedMachineLearning/blob/main/PageRank_and_HITS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZA0h8cs4jOHb"
      },
      "outputs": [],
      "source": [
        "%pylab inline \n",
        "from IPython.display import Image\n",
        "import numpy.linalg as LA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\def\\m#1{\\mathbf{#1}}$\n",
        "$\\def\\mb#1{\\mathbb{#1}}$\n",
        "$\\def\\c#1{\\mathcal{#1}}$\n",
        "\n",
        "# PageRank\n",
        "PageRank (PR) is an algorithm used by Google Search to rank web pages in their search engine results. It is named after both the term \"web page\" and co-founder Larry Page. PageRank is a way of measuring **the importance of website pages**. According to Google:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- PageRank works by counting the number and quality of links to a page to determine a rough estimate of how important the website is. The underlying assumption is that **more important websites are likely to receive more links from other websites**.\n",
        "\n",
        "\n",
        "- The PageRank algorithm outputs a probability distribution used to represent the likelihood that a person randomly clicking on links will arrive at any particular page.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AJPSHrm1jkn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algorithm \n",
        "Consider a **directed** weighted graph $G=(V,E,\\m{W})$ whose weight matrix decodes the webpage link structure:\n",
        "$$w_{ij} = \\begin{cases}\\#\\{\\text{link:}\\ i\\rightarrow j\\} & (i,j)\\in E  \\\\ 0 & \\text{Otherwise}\\end{cases} $$\n",
        "\n",
        "Define an out-degree vector $d_i^{(o)} = \\sum_{j=1}^nw_{ij}$, which measures the number of out-links\n",
        "from $i$. A diagonal matrix $D = \\text{diag}(d_i^{(o)})$ and a Markov matrix $M=D^{-1}W$ assumed for simplicity that all nodes have non-empty out-degree.\n",
        "\n",
        "This Markov chain accounts for a random walk according to the link structure of webpages. One would expect\n",
        "that stationary distributions of such random walks will disclose the importance of\n",
        "webpages: **the more visits, the more important**. \n",
        "\n",
        "There is one problem: $M$ may not be primitive, then the statinary distribution may not be unique. \n",
        "\n",
        "Introduce the following trick:\n",
        "\n",
        "- Let $P_\\alpha = \\alpha M + (1-\\alpha) E$, where $E = \\frac{1}{N}\\mb{1}\\mb{1}^\\top$ is a random surfing model, i.e., one\n",
        "can jump to any other webpage uniformly. So in the model $P_\\alpha$, a browser will play\n",
        "a dice: he will jump according to link structure with probability $\\alpha$ or randomly surf with probability $1-\\alpha$. \n",
        "\n",
        "- With $1>\\alpha>0$, the existence of random surfing model\n",
        "makes $P_\\alpha$ a positive matrix, whence there is a unique stationary $\\pi$. Google choose $\\alpha=0.85$ and in this case $\\pi$ gives PageRank scores. \n",
        "\n",
        "Implement it in HW. "
      ],
      "metadata": {
        "id": "P-yDAsM_pPyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cheating the PageRank\n",
        "\n",
        "- If there are many cross links between a small set of nodes (for\n",
        "example, Wikipedia), those nodes must appear to be high in\n",
        "PageRank.\n",
        "\n",
        "- Now you probably can figure out how to cheat PageRank. This\n",
        "phenomenon actually has been exploited by spam webpages, and\n",
        "even scholar citations. After learning the nature of PageRank, we\n",
        "should be aware of such mis-behaviors. "
      ],
      "metadata": {
        "id": "oAL4tZtHjY-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kleinberg's HITS algorithm\n",
        "In PageRank we consider out-degree $d^{(o)}$. How about in-degree $d^{(i)}_k=\\sum_{j}w_{jk}$?\n",
        "\n",
        "- High out-degree webpages can be regarded as hubs, as they provide\n",
        "more links to others. Like wikipedia. \n",
        "\n",
        "- High in-degree webpages\n",
        "are regarded as authorities, as they were cited by others intensively. Like great research paper. \n",
        "\n",
        "- Basically in/out-degrees can be used to rank webpages, which gives\n",
        "relative ranking as authorities/hubs.\n",
        "  \n",
        "   - $d^{(o)}_i = \\sum_{k}w_{ik}$ \n",
        "\n",
        "   - $d^{(i)}_j = \\sum_{k}w_{kj}$\n",
        "\n",
        "Jon Kleinbergâ€™s HITS algorithm gives similar results to\n",
        "in/out-degree ranking. It is based on singular value decomposition (SVD) of link matrix $\\m{W}$. \n",
        "\n",
        "\n",
        "### HITS-authority\n",
        "We use primary right singular vector of $\\m{W}$ as scores to give the ranking. To understand this, define $L_a = \\m{W}^\\top \\m{W}$\n",
        "\n",
        "- Primary right singular vector of $\\m{W}$ is just a primary eigenvector of\n",
        "nonnegative symmetric matrix $L_a$. \n",
        "\n",
        "- Since $L_a(i,j) = \\sum_k w_{ki}w_{kj}$,  thus it counts the number of\n",
        "references which cites both $i$ and $j$, i.e., $\\sum_k\\# \\{i\\leftarrow k \\rightarrow j\\}$. The\n",
        "higher value of $L_a(i,j)$ the more references received on the pair of\n",
        "nodes. Therefore eigenvector tend to rank the webpages according\n",
        "to authority.\n",
        "\n",
        "\n",
        "### HITS-hub\n",
        "We use primary left singular vector of $\\m{W}$ as scores to give the ranking. To understand this, define $L_h = \\m{W} \\m{W}^\\top$\n",
        "\n",
        "\n",
        "- Since $L_h(i,j) = \\sum_k w_{ik}w_{jk}$, which counts the number of links\n",
        "from both $i$ and $j$, hitting the same target, i.e., $\\sum_k\\# \\{i\\rightarrow k \\leftarrow j\\}$. Therefore eigenvector tend to rank the webpages according\n",
        "to hub."
      ],
      "metadata": {
        "id": "uFM0Q0hTlWeA"
      }
    }
  ]
}