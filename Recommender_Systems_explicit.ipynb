{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recommender Systems: explicit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPErSAuKUXFY2XWfM4oZvM0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yexf308/AdvancedMachineLearning/blob/main/Recommender_Systems_explicit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIMcki5QD9xQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1208f462-a1a1-425d-8a61-89b0e0d6d395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "%pylab inline \n",
        "from IPython.display import Image\n",
        "import numpy.linalg as LA\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refer to Prof. Hsieh [class lectures](http://web.cs.ucla.edu/~chohsieh/teaching/CS260_Winter2019/main.html) and [link](http://ethen8181.github.io/machine-learning/). "
      ],
      "metadata": {
        "id": "V51eEt3H5vZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\def\\m#1{\\mathbf{#1}}$\n",
        "$\\def\\mb#1{\\mathbb{#1}}$\n",
        "$\\def\\c#1{\\mathcal{#1}}$\n",
        "$\\def\\Tr{\\text{Tr}}$\n",
        "\n",
        "# Recommendation systems\n",
        "\n",
        "Recommender systems are systems which recommend items (such as movies, books, ads) to users based on various information, such as their past viewing/ purchasing behavior (e.g., which movies they rated high or low, which ads they clicked on), as well as optional “side information” such\n",
        "as demographics about the user, or information about the content of the item (e.g., its title, genre\n",
        "or price).\n",
        "\n",
        "# Explicit feedback\n",
        "we consider the simplest setting in which the user gives explicit feedback to the\n",
        "system in terms of a rating: a score from 1 to 5. \n",
        "\n",
        "- Let $A_{ui}\\in\\{1,2,3,4,5\\}$ be the rating that user $u$ gives to movie $i$. And $A\\in \\mb{R}^{M\\times N}$ where $M$ is\n",
        "the number of users, and $N$ is the number of movies. Typically this matrix will be very large but\n",
        "very sparse, since most users will not provide any feedback on most items. **We will assume the data is missing\n",
        "at random** because the user has not interacted with that movie. \n",
        "\n",
        "\n",
        "- **Netflix Prize:** A famous example of an explicit ratings matrix was made available by the movie streaming company\n",
        "Netflix. In 2006, they released a large dataset of 100,480,507 movie ratings (on a scale of 1 to 5)\n",
        "from 480,189 users of 17,770 movies. Despite the large size of the training set, the ratings matrix is\n",
        "still 99% sparse。 \n",
        "<img src=\"https://github.com/yexf308/AdvancedMachineLearning/blob/main/image/recom1.png?raw=true\" width=\"500\" />\n",
        "\n",
        "- **Matrix Factorization Approach:** Suppose we had $d$ topics for\n",
        "each user and movie. \n",
        "   - Describe movie $i$ with topics $H_i$, (How much is it action, romance, drama?) \n",
        "$$ H_i = [0.2, 0.01, 0.5]$$\n",
        "\n",
        "   - Describe user $u$ with topics $W_u$, (How much she/he likes action, romance, drama?)\n",
        "$$ W_u = [2.5, 0, 0.8]$$   \n",
        "\n",
        "   - The rating $Y_{ui}$ is the product of the two vectors $H_i, W_u$. \n",
        "   \n",
        "   $$ A_{ui} = W_u H_i^\\top = 2.5\\times 0.2 + 0.8 \\times 0.5 = 0.9$$\n",
        "\n",
        "   - Recommendations: sort movies user hasn’t watched by the rating $A_{ui}$. \n",
        "\n",
        "\n",
        "<img src=\"https://github.com/yexf308/AdvancedMachineLearning/blob/main/image/recom2.png?raw=true\" width=\"500\" />\n",
        "\n",
        "<img src=\"https://github.com/yexf308/AdvancedMachineLearning/blob/main/image/recom3.png?raw=true\" width=\"500\" />\n",
        "\n",
        "- Predictions in matrix form. But we don’t\n",
        "know topics of users and movies.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yn1wHQRSEo9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 1: Direct low rank solutions: Matrix Factorization Approach $A\\approx WH^\\top$\n",
        "\\begin{align}\n",
        "\\min_{W\\in \\mb{R}^{M\\times k}, H\\in \\mb{R}^{N\\times k}} \\sum_{(u,i)\\in \\Omega}(A_{ui}- W_u H_i^T)^2 + \\lambda \\left(\\|W\\|_F^2 + \\|H\\|_F^2\\right)\n",
        "\\end{align}\n",
        "\n",
        "- $A\\in \\mb{R}^{M\\times N}$  rating matrix.\n",
        "\n",
        "- $\\Omega=\\{(u,i)|A_{ui} \\text{ is observed. }\\}$\n",
        "\n",
        "- Regularized terms to avoid over-fitting\n",
        "\n",
        "- In practice, it is important to also allow for user-specific and item-specific baselines, by writing \n",
        "$$ A_{ui}=\\mu+b_u+c_i +W_u H_i^T$$\n",
        "\n",
        "\n",
        "\n",
        "Matrix factorization maps users/items to latent feature space $\\mb{R}^k$\n",
        "\n",
        "- $u$-th user, $u$-th row of $W$: $W_u$. \n",
        "\n",
        "- $i$-th movie, $i$-th row of $H$: $H_i$.\n",
        "\n",
        "- $W_uH_i^\\top$  measures the interaction between $i$th user and $j$th movie\n",
        "\n",
        "<img src=\"https://github.com/yexf308/AdvancedMachineLearning/blob/main/image/recom4.png?raw=true\" width=\"500\" />\n",
        "<img src=\"https://github.com/yexf308/AdvancedMachineLearning/blob/main/image/recom5.png?raw=true\" width=\"500\" />"
      ],
      "metadata": {
        "id": "JV3x1MUyO2g2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fully observed case: connection to SVD\n",
        "\n",
        "Assume no regularization and $Y$ is fully observed, the problem becomes\n",
        "\\begin{align}\n",
        "\\min_{W\\in \\mb{R}^{M\\times k}, H\\in \\mb{R}^{N\\times k}} \\sum_{(u,i)}(A_{ui}- W_u H_i^T)^2 = \\|A-WH^\\top\\|^2_F\n",
        "\\end{align}\n",
        "\n",
        "**Solution:** Perform singular value decomposition (SVD) on $A$ and keeps\n",
        "top $k$ singular values/vectors.\n",
        "\n",
        "Unfortunately, no closed form solution in partially observed case. So need to solve the optimization problem iteratively. \n",
        "\n"
      ],
      "metadata": {
        "id": "BOfPqz44ZEHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algorithm 1: ALS: Alternating Least Squares\n",
        "Objective function $f(W,H)$ is defined as follows\n",
        "\\begin{align}\n",
        "f(W,H):=\\frac{1}{2}\\sum_{(u,i)\\in \\Omega}(A_{ui}- W_u H_i^T)^2 + \\frac{1}{2}\\lambda \\left(\\|W\\|_F^2 + \\|H\\|_F^2\\right)\n",
        "\\end{align}\n",
        "\n",
        "Iteratively fix either $H$ or $W$ and optimize the other:\n",
        "- **Input:** partially observed matrix $A$, initial values of $W$, $H$. \n",
        "\n",
        "- For $t=1,2,\\dots$\n",
        "\n",
        " - Fix $W$ and update $H$: $H\\leftarrow \\arg\\min_H f(W,H) $.\n",
        "\n",
        " - Fix $H$ and update $W$: $W\\leftarrow \\arg\\min_W f(W,H) $.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x8xojCdZnbQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Define: $\\Omega_i = \\{u |(u,i)\\in \\Omega\\}$. \n",
        "\n",
        "- The subproblem: \n",
        "\\begin{align}\n",
        "&\\arg\\min_H \\frac{1}{2}\\sum_{(u,i)\\in \\Omega} (A_{ui}- (W H^T)_{ui})^2 +\\frac{1}{2}\\lambda \\|H\\|_F^2 \\\\\n",
        "&=\\sum_{i=1}^N \\arg\\min_{H_i}\\left(\\frac{1}{2}\\sum_{(u,i)\\in\\Omega}(A_{ui} - W_uH^\\top_i)^2+\\frac{\\lambda}{2}\\|H_i\\|^2\\right)\n",
        "\\end{align}\n",
        "\n",
        "  - $N$ ridge regression problems, each with $k$ variables\n",
        "\n",
        "  - Easy to parallelize. ($N$ independent ridge regressions)\n",
        "\n",
        "- The derivative with respect to $W_u$,\n",
        "\\begin{align}\n",
        "&\\frac{\\partial}{\\partial W_u}\\left(\\frac{1}{2}\\sum_{(u,i)\\in\\Omega}(A_{ui} - W_uH^\\top_i)^2+\\frac{\\lambda}{2}\\|W_u\\|^2\\right) \\\\\n",
        "& = -\\sum_{(u,i)\\in \\Omega}(A_{ui} - W_uH_i^\\top)H_i +\\lambda W_u = 0\n",
        "\\end{align}  \n",
        "  In the matrix form, the optimal solution for $W^*$ is  \n",
        "\\begin{align}\n",
        "&W_u^* (H^\\top H+\\lambda I)=  A_uH \\\\\n",
        "&W_u^* = A_uH(H^\\top H+\\lambda I)^{-1}\\\\\n",
        "&W^* = AH(H^\\top H+\\lambda I)^{-1}\n",
        "\\end{align}  \n",
        "\n",
        "- The derivative with respect to $H_i$,\n",
        "\\begin{align}\n",
        "&\\frac{\\partial}{\\partial H_i}\\left(\\frac{1}{2}\\sum_{(u,i)\\in\\Omega}(A_{ui} -  H_iW_u^\\top)^2+\\frac{\\lambda}{2}\\|H_i\\|^2\\right) \\\\\n",
        "& = -\\sum_{(u,i)\\in \\Omega}(A_{ui} - H_iW_u^\\top)W_u +\\lambda H_i = 0\n",
        "\\end{align}\n",
        "\n",
        "  In the matrix form, the optimal solution for $H^*$ is  \n",
        "\\begin{align}\n",
        "&H^*_i(W^\\top W+\\lambda I )= (A^\\top)_i W\\\\\n",
        "&H^*_i = (A^\\top)_i W(W^\\top W+\\lambda I )^{-1}\\\\\n",
        "&H^* =A^\\top W(W^\\top W+\\lambda I )^{-1}\n",
        "\\end{align}  \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Dsz4gAKjssg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algorithm 2: Stochastic Gradient Descent \n",
        "- $n_u^W$: number of nonzeroes in the $u$-th row of $A$.\n",
        "\n",
        "- $n_i^H$: number of nonzeroes in the $i$-th column of $A$.\n",
        "\n",
        "- Decompose the problem into $\\Omega$ components:\n",
        "\\begin{align}\n",
        "f(W,H) & =\\frac{1}{2}\\sum_{(u,i)\\in \\Omega}(A_{ui}- W_u H_i^T)^2 + \\frac{1}{2}\\lambda \\left(\\|W\\|_F^2 + \\|H\\|_F^2\\right)\\\\\n",
        "&= \\sum_{(u,i)\\in\\Omega}\\left(\\frac{1}{2}(A_{ui}- W_u H_i^T)^2+\\frac{\\lambda}{2}\\|W_u\\|_2^2+\\frac{\\lambda}{2}\\|H_i\\|_2^2\\right)\n",
        "\\end{align}\n",
        "The gradient of each component:\n",
        "\\begin{align}\n",
        "&\\nabla_{W_u}f_{u,i}(W,H)= (W_u H_i^T - A_{ui})H_i + \\lambda W_u \\\\\n",
        "& \\nabla_{H_i}f_{u,i}(W,H)= (W_u H_i^T - A_{ui})W_u + \\lambda H_i\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "vsPQtXcAskch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algorithm\n",
        "- **Input:** partially observed matrix $A$, initial values of $W$ , $H$. \n",
        "\n",
        "- For $t = 1, 2,\\dots$, \n",
        "  \n",
        "  - Randomly pick a pair $(i,j)\\in \\Omega$.\n",
        "\n",
        "  - $W_u \\leftarrow (1-\\eta_t \\lambda)W_u -\\eta_t (W_uH_i^\\top -A_{ui})H_i$\n",
        "\n",
        "  - $H_i \\leftarrow (1-\\eta_t \\lambda)H_i -\\eta_t (W_uH_i^\\top -A_{ui})W_u$\n",
        "\n",
        "\n",
        "\n",
        "**Time complexity:** $O(k)$ per iteration; $O(|\\Omega|k)$ for one pass of all observed entries. \n",
        "\n",
        "### Parallelize SGD\n",
        "\n",
        "- Two SGD update on $(u_1, i_1)$ and $(u_2, i_2)$ in the same time:\n",
        "\n",
        "   - $(u_1, i_1)$ Updates $W_{u_1}$ and $H_{i_1}$. \n",
        "\n",
        "   - $(u_2, i_2)$ Updates $W_{u_2}$ and $H_{i_2}$. \n",
        "\n",
        "   - Confliction happens when $u_1=u_2$ or $i_1=i_2$.\n",
        "\n",
        "How to avoid conflict?  Gemulla et al., “Large-Scale Matrix Factorization with Distributed Stochastic Gradient Descent”.  \n",
        "\n",
        "<img src=\"https://github.com/yexf308/AdvancedMachineLearning/blob/main/image/recom_SGD1.png?raw=true\" width=\"600\" />\n",
        "\n",
        "<br>\n",
        "<img src=\"https://github.com/yexf308/AdvancedMachineLearning/blob/main/image/recom_SGD2.png?raw=true\" width=\"200\" />\n",
        "<img src=\"https://github.com/yexf308/AdvancedMachineLearning/blob/main/image/recom_SGD3.png?raw=true\" width=\"200\" />\n",
        "<img src=\"https://github.com/yexf308/AdvancedMachineLearning/blob/main/image/recom_SGD4.png?raw=true\" width=\"200\" />\n",
        "\n"
      ],
      "metadata": {
        "id": "wAQmlDxivBJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 2: Matrix-norm\tMinimization\n",
        "Previously, we need to specify the dimension of the latent feature space $k$ and this is not a convex problem so there are many local optima.\n",
        "\n",
        "We can rephase this problem to the following \n",
        "\\begin{align}\n",
        "\\min_{\\Theta} \\text{rank}(\\Theta), \\ \\ \\ \\text{subject to } \\Theta_{ui} = A_{ui} \\text{ for } (u,i)\\in \\Omega. \n",
        "\\end{align}\n",
        "\n",
        "The issue is: \n",
        "- it is NP-hard!!\n",
        "\n",
        "- You cannot hope to get exact matching. \n",
        "\n",
        "- Previous approach is kind of relaxation of this problem. \n",
        "\n",
        "### Eigenvalue\tDecompositions\tfor\tPSD\tMatrices\n",
        "\n",
        "Given a PSD matrix $\\m{M}\\in \\mb{R}^{D\\times D}$, by definition, eigenvalues $\\lambda_i\\ge 0$ for $i=1,\\dots, D$.\n",
        "\n",
        "- $\\text{rank}(\\m{M})=|\\{\\lambda_i: \\lambda_i\\ge 0\\}|=\\|\\vec\\lambda\\|_0$. \n",
        "\n",
        "- We can use 1-norm to approximate, i.e., $\\|\\vec\\lambda\\|_0\\approx \\|\\vec\\lambda\\|_1=\\sum_{i=1}^D|\\lambda_i|=\\text{trace}(\\m{M})$. \n",
        "\n",
        "- If $A$ is PSD, then \n",
        "\\begin{align}\n",
        "\\min_{\\Theta} \\text{rank}(\\Theta)= \\|\\vec\\lambda\\|_0,\\ \\  \\text{subject to } \\Theta_{ui}=A_{ui}, \\Theta\\ge 0, \\text{ for } (u,i)\\in \\Omega.\n",
        "\\end{align}\n",
        "is approximated by \n",
        "\\begin{align}\n",
        "\\min_{\\Theta} \\text{Trace}(\\Theta)= \\|\\vec\\lambda\\|_1,\\ \\  \\text{subject to } \\Theta_{ui}=A_{ui}, \\Theta\\ge 0, \\text{ for } (u,i)\\in \\Omega.\n",
        "\\end{align}\n",
        "\n",
        "- For PSD matrix, eigenvalue decompsition and Singular value decomposition are the same. $\\m{M}=P\\Lambda P^{-1}=U\\Sigma V^\\top$. For rectangular matrices, diagonal matrix with entries $\\sigma_i(\\Theta)\\ge 0$. So we can use the nuclear norm of $\\Theta$ to approximate, i.e, \n",
        "\\begin{align}\n",
        "\\min_{\\Theta} \\|\\Theta\\|_*=\\sum_{i=1}^D \\sigma_i(\\Theta),\\ \\  \\text{subject to } \\Theta_{ui}=A_{ui}, \\text{ for } (u,i)\\in \\Omega.\n",
        "\\end{align}\n",
        " It is a convex problem!!\n",
        "\n",
        "- Again there may not be feasible solution. We will further relax to \n",
        "\\begin{align}\n",
        "\\min_{\\Theta}\\sum_{(u,i)\\in \\Omega}(A_{ui}- \\Theta_{ui})^2 + \\lambda \\|\\Theta\\|_* \n",
        "\\end{align}\n",
        " It is again a convex problem and can be solved by semidefinite programming. \n",
        "\n",
        "\n",
        "- Theorem: (Candes, Recht 08)\n",
        "   - If\tthere\tis\ta\ttrue\tmatrix\tof\trank $k$ and has the size of $N\\times M$ and assume $N>M$. \n",
        "\n",
        "   - And, we observe at least $CkN^{1.2}\\log(N)$ random entries of the true matrix. \n",
        "\n",
        "   - (Under certain conditions) True matrix is recovered exactly with high probability via convex nuclear norm minimization. The solution is unique. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3ItcufukFLXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison \n",
        "- Nuclear\tNorm\tMinimization\n",
        "\\begin{align}\n",
        "\\min_{\\Theta}\\sum_{(u,i)\\in \\Omega}(A_{ui}- \\Theta_{ui})^2 + \\lambda \\|\\Theta\\|_* \n",
        "\\end{align}\n",
        "   - Pro: Convex, global optimal, close to truth. \n",
        "\n",
        "   - Con: SDP solvers are very slow when $\\Theta$ is very large (like Netflix Prize). It is still in polynomial time. \n",
        "\n",
        "- Direct low rank solutions\n",
        "\\begin{align}\n",
        "\\min_{W\\in \\mb{R}^{M\\times k}, H\\in \\mb{R}^{N\\times k}} \\sum_{(u,i)\\in \\Omega}(A_{ui}- W_u H_i^T)^2 + \\lambda \\left(\\|W\\|_F^2 + \\|H\\|_F^2\\right)\n",
        "\\end{align}\n",
        "\n",
        "  - Pro: No. of parameters are smaller and has very fast solvers. \n",
        "\n",
        "  - Con: Many local optimal.\n",
        "\n",
        "\n",
        "- Connection (Burer Monterio 04)\n",
        "  - $$\\|\\Theta\\|_*=\\left\\{\\min_{W, H} \\frac{1}{2}\\|W\\|_F^2 + \\frac{1}{2}\\|H\\|_F^2: \\Theta= WH^\\top \\right\\} $$ \n",
        "\n",
        "  - Direct low rank solutions is a non-convex approximatin of Nuclear\tNorm\tMinimization. \n",
        "\n",
        "  - If we pick rank $k$ to be slightly larger than $\\text{rank}(\\Theta)$, the local optima of Direct low rank solutions is actually global optima in Nuclear\tNorm\tMinimization with high probability. \n"
      ],
      "metadata": {
        "id": "jBWSgdTza2gv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 3: Nonnegative Matrix Factorization\n",
        "\n",
        "In the description, we would like to have $W$ and $H$ to be nonnegative matrices. \n",
        "- $W$: how much the user like for each topic\n",
        "\n",
        "- $H$: how much the item/movie contributes to a topic. \n",
        "\n",
        "But both method above can result negative entries. \n",
        "Now it becomes a constrained optimization problem.  \n",
        "\n",
        "\\begin{align}\n",
        "\\min_{W\\in \\mb{R}^{M\\times k}, H\\in \\mb{R}^{N\\times k}} \\frac{1}{2}\\sum_{(u,i)\\in \\Omega}(A_{ui}- W_u H_i^T)^2 + \\frac{\\lambda}{2} \\left(\\|W\\|_F^2 + \\|H\\|_F^2\\right), \\text{ subject to } W\\ge 0, H\\ge 0. \n",
        "\\end{align}\n",
        "\n",
        "### Algorithm: Projected\tGradient\n",
        "\n",
        "<img src=\"https://github.com/yexf308/AdvancedMachineLearning/blob/main/image/proj.png?raw=true\" width=\"300\" />\n",
        "\n",
        "- Standard optimization: \n",
        "  - want to minimize: $\\min_{\\Theta}f(\\Theta)$\n",
        "\n",
        "  - In stochastic gradient descent method \n",
        "  $$\\Theta^{(t+1)} \\leftarrow \\Theta^{(t)}-\\eta_t\\nabla f(\\Theta^{(t)}) $$\n",
        "\n",
        "\n",
        "- Constrained\toptimization:  \n",
        "   \n",
        "    - Given\tconvex\tset\t$C$\tof\tfeasible\tsolutions.\n",
        "\n",
        "    - Want to find optima within $C$: $\\min_{\\Theta\\in C}f(\\Theta)$. \n",
        "\n",
        "- Projected gradient: \n",
        "  - Take a gradient step and ignore constraints \n",
        "  $$\\tilde \\Theta^{(t+1)} \\leftarrow \\Theta^{(t)}-\\eta_t\\nabla f(\\Theta^{(t)}) $$\n",
        "\n",
        "  - Project into feasible set: it is always convex and often easy to compute\n",
        "  $$\\Pi_c(\\theta)=\\arg\\min_{\\beta\\in C}\\|\\theta-\\beta\\|_2^2 $$\n",
        "  $$ \\Theta^{(t+1)}= \\Pi_c(\\tilde \\Theta^{(t+1)})$$\n",
        "\n",
        "\n",
        "**Input:** partially observed matrix $A$, initial values of $W$ , $H$. \n",
        "\n",
        "- For $t = 1, 2,\\dots$, \n",
        "  \n",
        "  - Randomly pick a pair $(i,j)\\in \\Omega$.\n",
        "\n",
        "  - $\\tilde W_u \\leftarrow (1-\\eta_t \\lambda)W_u -\\eta_t (W_uH_i^\\top -A_{ui})H_i$\n",
        "\n",
        "  - $W_u = (\\tilde W_u)_{+}$, i.e., set all negative coordinate to 0. \n",
        "\n",
        "  - $\\tilde H_i \\leftarrow (1-\\eta_t \\lambda)H_i -\\eta_t (W_uH_i^\\top -A_{ui})W_u$\n",
        "\n",
        "  - $H_i = (\\tilde H_i)_{+}$, i.e., set all negative coordinate to 0. \n",
        "\n",
        "\n",
        "  \n",
        "### Algorithm: Lee and Seung's multiplicative update rule\n",
        "The optimization problem is equivalent with the following matrix form \n",
        "\\begin{align}\n",
        "\\min_{W\\in \\mb{R}^{M\\times k}, H\\in \\mb{R}^{N\\times k}} \\|A-WH^\\top\\|_F^2 + \\lambda \\left(\\|W\\|_F^2 + \\|H\\|_F^2\\right), \\text{ subject to } W\\ge 0, H\\ge 0. \n",
        "\\end{align}\n",
        "\n",
        "Some background knowledge:\n",
        "\n",
        "- $\\|X\\|_F^2 = \\Tr(X^\\top X) $\n",
        "\n",
        "- $\\nabla_X\\Tr(AX)=A^\\top$\n",
        "\n",
        "- $\\nabla_X\\Tr(XA^\\top)=A$\n",
        "\n",
        "- $ \\nabla_X\\Tr(XAX^\\top)=X(A+A^\\top)$\n",
        "\n",
        "Note \n",
        "\\begin{align}\n",
        "\\|A-WH^\\top\\|_F^2 &= \\Tr\\left((A-WH^\\top)^\\top (A-WH^\\top)\\right) \\\\\n",
        "& = \\Tr(A^\\top A -A^\\top WH^\\top - HW^\\top A+ HW^\\top WH^\\top ) \\\\\n",
        "& = \\Tr(A^\\top A) - \\Tr(A^\\top WH^\\top) - \\Tr(HW^\\top A)+\\Tr(HW^\\top WH^\\top)\n",
        "\\end{align}\n",
        "The non-negative matrix factorization problem is non-convex in $W$ and $H$ but it is convex in only $W$ or only $H$. To optimize the above problem, we use a block coordinate descent scheme where we optimize with respect to $W$ first while keeping $H$ fixed and then vice versa.\n",
        "\\begin{align}\n",
        "&1. \\nabla_W \\Tr(A^\\top WH^\\top) =\\nabla_W \\Tr(H^\\top A^\\top W) = (H^\\top A^\\top)^\\top = AH \\\\\n",
        "&2. \\nabla_W \\Tr(HW^\\top A) = \\nabla_W \\Tr(W^\\top AH) = AH \\\\\n",
        "&3. \\nabla_W\\Tr(HW^\\top WH^\\top) = \\nabla_W\\Tr(WH^\\top HW^\\top) =2WH^\\top H \n",
        "\\end{align}\n",
        "\n",
        "The derivatives with respect to $H$ can computed similarly. So\n",
        "\\begin{align}\n",
        "&\\nabla_W f(W,H) = -AH + WH^\\top H + \\lambda W = (WH^\\top-A) H+ \\lambda W \\\\\n",
        "&\\nabla_H f(W,H) = -W^\\top A + W^\\top WH^\\top +\\lambda H  =W^\\top(WH^\\top-A) +\\lambda H\n",
        "\\end{align}\n",
        "\n",
        "Using the above derivatives,\n",
        "\\begin{align}\n",
        "&W \\leftarrow (1-\\eta_W \\lambda) W-\\eta_W(WH^\\top-A) H\\\\\n",
        "&H\\leftarrow (1-\\eta_H \\lambda) H- \\eta_H W^\\top(WH^\\top-A)\n",
        "\\end{align}\n",
        "\n",
        "Traditionally in gradient descent, the learning rates are positive but since the subtraction of terms in the update rules can lead to negative elements. \n",
        "\n",
        "Lee and Seung proposed to use *adaptive learning rates* to avoid subtraction and thus the production of negative elements. The learning rates are defined in such a way that there is no subtraction in the update rules. \n",
        "\n",
        "If we set \n",
        "$$ \\eta_{W_{ij}} = \\frac{W_{ij}}{\\lambda W_{ij} + (WH^\\top H)_{ij}}$$\n",
        "$$\\eta_{H_{ij}} =\\frac{H_{ij}}{\\lambda H_{ij} + (W^\\top W H^\\top)_{ij}}$$\n",
        "we arrive at the given update rules.\n",
        "$$ W_{ij}\\leftarrow \\frac{W_{ij} (AH)_{ij}}{\\lambda W_{ij} + (WH^\\top H)_{ij}}$$\n",
        "$$H_{ij} \\leftarrow \\frac{H_{ij}(W^\\top A)_{ij}}{\\lambda H_{ij} + (W^\\top W H^\\top)_{ij}}  $$\n",
        "Note that the updates are done on an element by element basis not matrix multiplication. \n",
        "\n",
        "Note that the multiplicative factors for $W$ and $H$, then $\\frac{(AH)_{ij}}{(WH^\\top H)_{ij}}$ and $\\frac{(W^\\top A)_{ij}}{(W^\\top W H^\\top)_{ij}}$ are ones, when $A = W H^\\top$.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Input:** partially observed matrix $A$, initial values of non-negative $W$ , $H$: \n",
        "\n",
        "Update the values in $W$ and $H$ by computing the following, with $t$ as an index of the iteration.\n",
        "\n",
        "- For $t = 1, 2,\\dots$,\n",
        "  - $ W_{ij}^{(t+1)}\\leftarrow \\frac{W_{ij}^{(t)} (AH^{(t)})_{ij}}{\\lambda W^{(t)}_{ij} + (W^{(t)}(H^{(t)})^\\top H^{(t)})_{ij}}$\n",
        "\n",
        "  - $H_{ij}^{(t+1)} \\leftarrow \\frac{H_{ij}^{(t)}((W^{(t+1)})^\\top A)_{ij}}{\\lambda H^{(t)}_{ij} + ((W^{(t+1)})^\\top W^{(t+1)} (H^{(t)})^\\top)_{ij}}  $\n",
        "\n",
        "  - Until $W^{(t)}$ and $H^{(t)}$ are stable.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uhZcZYJ-mHDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 4: Feature-based recommendation: Matrix completion with features\n",
        "we have assumed that the only information available to the predictor are the integer id of the\n",
        "user and the integer id of the item/movie. This is an extremely impoverished representation, and will fail to work if we encounter a new user or new item (the so-called **cold start** problem). To overcome this, we need to leverage “side information”, beyond just the id of the user/item.\n",
        "\n",
        "**Input:**  rating matrix $A\\in \\mb{R}^{M\\times N}$, user feature $X\\in \\mb{R}^{M\\times d_1}$ and item feature $Y\\in \\mb{R}^{N\\times d_2}$. \n",
        "\n",
        "**Goal:** predict unknown ratings.\n",
        "## Inductive Matrix Completion (IMC)\n",
        "$$ A \\approx XWH^\\top Y^\\top$$\n",
        "where $X\\in \\mb{R}^{M\\times d_1}, W\\in \\mb{R}^{d_1\\times k}, H\\in \\mb{R}^{d_2\\times k}, Y\\in \\mb{R}^{N\\times d_2}$. Note here $W$ and $H$ are independent with number of users and items.\n",
        "\n",
        "The optimization problem becomes\n",
        "\\begin{align}\n",
        "\\min_{W\\in \\mb{R}^{d_1\\times k}, H\\in \\mb{R}^{d_2\\times k}} \\frac{1}{2}\\sum_{(u,i)\\in \\Omega}(A_{ui}- X_u W H^\\top Y_i^\\top)^2 + \\frac{\\lambda}{2} \\left(\\|W\\|_F^2 + \\|H\\|_F^2\\right)\n",
        "\\end{align}\n",
        "- $X_u$ is the feature for user $u$ and $Y_i$ is the feature for user $i$. \n",
        "\n",
        "- $X_uW\\in \\mb{R}^k$: $k$-dimensional embedding of user $u$.\n",
        "\n",
        "- $H^\\top Y_i^\\top \\in \\mb{R}^k$: $k$-dimensional embedding of item $i$.\n",
        "\n",
        "- Inner product in the $k$-dimensional embedding space gives the predicted value. "
      ],
      "metadata": {
        "id": "XkkbGS6k7YnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Factorization machine \n",
        "Observation: Recommendation systems can be transformed to classification or regression.\n",
        "$$(u,i, A_{ui}) \\Rightarrow (\\m{z}^{(u,i)}, A_{ui}) $$\n",
        "where $\\m{z}^{(i,j)}$ is the feature extracted for user $u$ and item $i$. \n",
        "\n",
        "Example: $\\m{z}^{(u,i)}=[X_u, Y_i]$ \n",
        "\n",
        "<img src=\"https://github.com/yexf308/AdvancedMachineLearning/blob/main/image/fact.png?raw=true\" width=\"600\" />"
      ],
      "metadata": {
        "id": "lo8JiNAzqriQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coding example: MovieLens\n",
        "\n",
        "We start by loading some sample data to make this a bit more concrete. For this introduction, we'll be using the MovieLens dataset. The website has datasets of various sizes, but we just start with the smallest one MovieLens 100K Dataset. This dataset consists of 100,000 movie ratings by users (on a 1-5 scale). The main data set u.data file consists of four columns (tab-delimited), including user-id (starting at 1), item-id (starting at 1), rating, and timestamp (we won't be using this field).\n",
        "\n"
      ],
      "metadata": {
        "id": "lpsKUEF4yYJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip -O ml-100k.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aJbnkBfw4X6",
        "outputId": "558cd420-2253-4a8d-9c13-32123206c1a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-24 03:46:37--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  11.2MB/s    in 0.4s    \n",
            "\n",
            "2022-02-24 03:46:38 (11.2 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ml-100k.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPZVk-wuxGQ7",
        "outputId": "5ab486aa-4dda-4534-fc6b-3d96b15cf776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ml-100k.zip\n",
            "   creating: ml-100k/\n",
            "  inflating: ml-100k/allbut.pl       \n",
            "  inflating: ml-100k/mku.sh          \n",
            "  inflating: ml-100k/README          \n",
            "  inflating: ml-100k/u.data          \n",
            "  inflating: ml-100k/u.genre         \n",
            "  inflating: ml-100k/u.info          \n",
            "  inflating: ml-100k/u.item          \n",
            "  inflating: ml-100k/u.occupation    \n",
            "  inflating: ml-100k/u.user          \n",
            "  inflating: ml-100k/u1.base         \n",
            "  inflating: ml-100k/u1.test         \n",
            "  inflating: ml-100k/u2.base         \n",
            "  inflating: ml-100k/u2.test         \n",
            "  inflating: ml-100k/u3.base         \n",
            "  inflating: ml-100k/u3.test         \n",
            "  inflating: ml-100k/u4.base         \n",
            "  inflating: ml-100k/u4.test         \n",
            "  inflating: ml-100k/u5.base         \n",
            "  inflating: ml-100k/u5.test         \n",
            "  inflating: ml-100k/ua.base         \n",
            "  inflating: ml-100k/ua.test         \n",
            "  inflating: ml-100k/ub.base         \n",
            "  inflating: ml-100k/ub.test         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
        "df = pd.read_csv('ml-100k/u.data', sep = '\\t', names = names)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "Nluop7ZqxuAu",
        "outputId": "309954bc-ec03-4db9-d5bb-6d762b644fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cee5feba-1df0-4c8b-b9c4-a8d8e22d6b6d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cee5feba-1df0-4c8b-b9c4-a8d8e22d6b6d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cee5feba-1df0-4c8b-b9c4-a8d8e22d6b6d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cee5feba-1df0-4c8b-b9c4-a8d8e22d6b6d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   user_id  item_id  rating  timestamp\n",
              "0      196      242       3  881250949\n",
              "1      186      302       3  891717742\n",
              "2       22      377       1  878887116\n",
              "3      244       51       2  880606923\n",
              "4      166      346       1  886397596"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the only data that we have is how each user interacted or rated each item. Given this information, collaborative filtering will start by constructing a user-item matrix with each distinct user being the row, item being the column and the value for each cell will simply be the rating that the user gave to the item. Apart from building the matrix, we will also print out some other information to help us understand our data a bit better.\n",
        "\n"
      ],
      "metadata": {
        "id": "ATBF8TrAyvzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the rating matrix A_{ui}, remember to\n",
        "# subract the user and item id by 1 since\n",
        "# the indices starts from 0\n",
        "n_users = df['user_id'].unique().shape[0]\n",
        "n_items = df['item_id'].unique().shape[0]\n",
        "A = np.zeros((n_users, n_items)) # we are not using sparsity here. \n",
        "for row in df.itertuples(index = False):\n",
        "    A[row.user_id - 1, row.item_id - 1] = row.rating\n",
        "\n",
        "# compute the non-zero elements in the rating matrix\n",
        "matrix_size = np.prod(A.shape)\n",
        "interaction = np.flatnonzero(A).shape[0]\n",
        "sparsity = 100 * (interaction / matrix_size)\n",
        "\n",
        "print(f'dimension: {A.shape}')\n",
        "print(f'sparsity: {sparsity}%')\n",
        "A\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0hC-Xr23Odj",
        "outputId": "ed8d5f50-e59a-4499-c5cf-037905d4ca58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dimension: (943, 1682)\n",
            "sparsity: 6.304669364224531%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5., 3., 4., ..., 0., 0., 0.],\n",
              "       [4., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [5., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 5., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the information above, we know there are 943 unique users, 1682 unique items. Within the rating matrix, only 6.3% of the cells have a value, although we filled in empty ratings as 0, we should not assume these values to truly be zero. More appropriately, they are just missing entries. This kind of sparsity is extremely common in recommendation system, where people seldom give ratings to things that they have purchased. One thing to note is that if the sparsity of the matrix is below 1% (rule of thumb), then the dataset might be too sparse to perform any sort of modeling.\n",
        "\n",
        "One tricky thing about splitting the data into training and testing is that: In supervise machine learning we normally build the training and testing holdout set by randomly splitting the rows. In those cases, this idea works, because we have a model with features/target that we are trying to fit a function to. For recommender systems with collaborative filtering (no features), this just won't work anymore, because all of the items/users need to be available when the model is first built. So what we do instead is mask a random sample of the user/item ratings to validate and compare how well the recommender system did in predicting the ratings of those masked values. In our case, given we already know each user has given more than 10 ratings, what we'll do is for every user, we remove 10 of the item ratings and and assign them to the test set. The testing matrix is printed below, as hopefully, you can see that some of the values are indeed different from the original rating matrix.\n",
        "\n"
      ],
      "metadata": {
        "id": "s1y_-Myf6JPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train_test(A):\n",
        "    \"\"\"\n",
        "    split into training and test sets,\n",
        "    remove 10 ratings from each user\n",
        "    and assign them to the test set\n",
        "    \"\"\"\n",
        "    test = np.zeros(A.shape)\n",
        "    train = A.copy()\n",
        "    for user in range(A.shape[0]):\n",
        "        test_index = np.random.choice(\n",
        "            np.flatnonzero(A[user]), size = 10, replace = False)\n",
        "\n",
        "        train[user, test_index] = 0.0\n",
        "        test[user, test_index] = A[user, test_index]\n",
        "        \n",
        "    # assert that training and testing set are truly disjoint\n",
        "    assert np.all(train * test == 0)\n",
        "    return train, test\n",
        "\n",
        "train, test = create_train_test(A)"
      ],
      "metadata": {
        "id": "9bOHz7H16Lvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MF_ALS:\n",
        "    \"\"\"\n",
        "    Train a matrix factorization model using Alternating Least Squares\n",
        "    to predict empty entries in a matrix\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    n_iters : int\n",
        "        number of iterations to train the algorithm\n",
        "        \n",
        "    n_factors : int\n",
        "        number of latent factors to use in matrix \n",
        "        factorization model, some machine-learning libraries\n",
        "        denote this as rank\n",
        "        \n",
        "    reg : float\n",
        "        regularization term for item/user latent factors,\n",
        "        since lambda is a keyword in python we use reg instead\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_iters, n_factors, reg):\n",
        "        self.reg = reg\n",
        "        self.n_iters = n_iters\n",
        "        self.n_factors = n_factors  \n",
        "\n",
        "    def _als_step(self, ratings, fixed_matrix):\n",
        "        \"\"\"\n",
        "        when updating the user matrix,\n",
        "        the item matrix is the fixed vector and vice versa\n",
        "        \"\"\"\n",
        "        A = fixed_matrix.T.dot(fixed_matrix) + np.eye(self.n_factors) * self.reg\n",
        "        b = ratings.dot(fixed_matrix)\n",
        "        \n",
        "        solve_matrix =np.linalg.solve(A,b.T).T\n",
        "        return solve_matrix\n",
        "\n",
        "\n",
        "    def predict(self):\n",
        "        \"\"\"predict ratings for every user and item\"\"\"\n",
        "        pred = self.user_factors.dot(self.item_factors.T)\n",
        "        return pred    \n",
        "\n",
        "    def compute_mse(self, train, pred):\n",
        "        \"\"\"ignore zero terms prior to comparing the mse\"\"\"\n",
        "        train_ravel = train.ravel()\n",
        "        pred_ravel  = pred.ravel()\n",
        "        mask = np.nonzero(train_ravel)\n",
        "        mse = np.sqrt(np.sum( (train_ravel[mask]- pred_ravel[mask])**2 )/shape(mask)[1])\n",
        "        return mse\n",
        "\n",
        "    def fit(self, train):\n",
        "        \"\"\"\n",
        "        pass in training to record\n",
        "        model convergence, assuming  dataset is in the form\n",
        "        of User x Item matrix with cells as ratings\n",
        "        \"\"\"\n",
        "        self.n_user, self.n_item = train.shape\n",
        "        self.user_factors = np.random.random((self.n_user, self.n_factors))\n",
        "        self.item_factors = np.random.random((self.n_item, self.n_factors))\n",
        "        \n",
        "        # record the training  for every iteration\n",
        "        # to show convergence later\n",
        "        self.train_mse_record = []   \n",
        "        for _ in range(self.n_iters):\n",
        "            self.user_factors = self._als_step(train,   self.item_factors)\n",
        "            self.item_factors = self._als_step(train.T, self.user_factors) \n",
        "            pred = self.predict()\n",
        "            train_mse = self.compute_mse(train, pred)\n",
        "            self.train_mse_record.append(train_mse)\n",
        "        \n",
        "        return self    \n",
        "\n",
        "\n",
        "    def validation(self, test):\n",
        "        \"\"\" \n",
        "        pass in testing to validate the performance of test data.\n",
        "        \"\"\"\n",
        "        pred = self.predict()\n",
        "        test_mse = self.compute_mse(test, pred)\n",
        "        print(f'MSE for testing data is {test_mse}')\n",
        "\n",
        "        return test_mse  \n",
        "\n",
        "\n",
        "    \n",
        "         \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sJyLBt24mJXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curve(model):\n",
        "        \"\"\"visualize the training/testing loss\"\"\"\n",
        "        linewidth = 3\n",
        "        plt.plot(model.train_mse_record, label = 'Train', linewidth = linewidth)\n",
        "        plt.xlabel('iterations')\n",
        "        plt.ylabel('MSE')\n",
        "        plt.legend(loc = 'best') "
      ],
      "metadata": {
        "id": "JBNOSNns-k4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "als = MF_ALS(n_iters = 100, n_factors = 20, reg = 0.01)\n",
        "als.fit(train)\n",
        "plot_learning_curve(als)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "xM0cjugy8LfD",
        "outputId": "0c5897e7-16d5-4136-cde9-5dc2d31c801f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "als.validation(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgtynZwanYjt",
        "outputId": "49e8a458-7ccc-4d68-d86d-12b128f6a683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE for testing data is 2.8405692625899395\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.8405692625899395"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_factors_span = arange(10,30)\n",
        "testing_MSE_store = zeros(len(n_factors_span))\n",
        "for i, n_factors_i in enumerate(n_factors_span):\n",
        "  als = MF_ALS(n_iters = 50, n_factors = n_factors_i, reg = 0.01)\n",
        "  als.fit(train)\n",
        "  testing_MSE_store[i]=als.validation(test)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeaXRmgro6fK",
        "outputId": "eaa9aa5b-94ae-4239-b71c-5dfb9d3c204a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE for testing data is 2.8405644280234226\n",
            "MSE for testing data is 2.835107285194301\n",
            "MSE for testing data is 2.8286890132778963\n",
            "MSE for testing data is 2.8228569248447943\n",
            "MSE for testing data is 2.821470851858986\n",
            "MSE for testing data is 2.819089228632184\n",
            "MSE for testing data is 2.8161712382713158\n",
            "MSE for testing data is 2.81710310928307\n",
            "MSE for testing data is 2.8165245762804454\n",
            "MSE for testing data is 2.8164192396570464\n",
            "MSE for testing data is 2.8170657239208294\n",
            "MSE for testing data is 2.8183446951732822\n",
            "MSE for testing data is 2.821035117190946\n",
            "MSE for testing data is 2.8235649008709474\n",
            "MSE for testing data is 2.825005868079568\n",
            "MSE for testing data is 2.8266812688275826\n",
            "MSE for testing data is 2.831181544932907\n",
            "MSE for testing data is 2.8348084408810124\n",
            "MSE for testing data is 2.837470150505845\n",
            "MSE for testing data is 2.8406120647270314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scatter(n_factors_span, testing_MSE_store)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "eQLikI1Cp-RH",
        "outputId": "84ccc565-4835-4990-f6b9-39ad5232545c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fd4c2adde50>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}